{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18.5\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "#Script that performs ML Task 7 for an antigen. \n",
    "#Usage in command line:\n",
    "#python ThisFile.py fileInput condition=1 removeDummies=false externalTestFile\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "#tf.keras.backend.set_floatx('float64') problems with float32 versus float64. Don't get.\n",
    "\n",
    "runningInCommandLine = False   # write false for jupyter, then more plotting available\n",
    "\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import os\n",
    "import random\n",
    "import urllib\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import math\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, matthews_corrcoef\n",
    "\n",
    "if(not(runningInCommandLine)):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "#Hides the presence of the GPU, to avoid problems on immunhub\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "print(np.__version__) #should be 1.18.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileInput = \"T7_1ADQ_A_Task1_SlicesBalancedData.txt_A.txt\"\n",
    "condition=1                #1: Normal, 3: Shuffled\n",
    "removeDummies = \"false\"\n",
    "externalTestFile = \"TestDatasetFor1ADQ_A_Task1_SlicesBalancedData.txt\"\n",
    "\n",
    "if(runningInCommandLine):\n",
    "    if(len(sys.argv) > 1):\n",
    "        fileInput = sys.argv[1]\n",
    "\n",
    "    if(len(sys.argv) > 2):\n",
    "        condition = int(sys.argv[2])\n",
    "\n",
    "    if(len(sys.argv) > 3):\n",
    "        architecture = sys.argv[3]\n",
    "        \n",
    "    if(len(sys.argv) > 4):\n",
    "        removeDummies = sys.argv[4]\n",
    "        if(removeDummies == \"True\" or removeDummies == \"TRUE\"):\n",
    "            removeDummies = \"true\"\n",
    "        if(removeDummies == \"False\" or removeDummies == \"FALSE\"):\n",
    "            removeDummies = \"false\"\n",
    "\n",
    "    if(len(sys.argv) > 5):\n",
    "        externalTestFile = sys.argv[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the one hot encoding functions and reverse\n",
    "alphabet = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "# define a mapping of chars to integers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "\n",
    "def hotEncodingAAString(myString):\n",
    "    onehot_encoded = list()\n",
    "    integer_encoded = [char_to_int[char] for char in myString]\n",
    "    for value in integer_encoded:\n",
    "        letter = [0 for _ in range(len(alphabet))]\n",
    "        letter[value] = 1\n",
    "        if(removeDummies == \"true\"):\n",
    "            onehot_encoded.append(letter[0:len(alphabet)-2])\n",
    "        else:\n",
    "            onehot_encoded.append(letter)\n",
    "    return onehot_encoded\n",
    "\n",
    "#input: [0,0,...,1,0,0]\n",
    "def retrieveAA(onehot_encodedAA):\n",
    "    #print(\"AA\", onehot_encodedAA)\n",
    "    #if(sum(onehot_encodedAA) != 1):\n",
    "    #    return '?'\n",
    "    foundAA = '?'\n",
    "    for i in range(len(onehot_encodedAA)):\n",
    "        if(onehot_encodedAA[i] == 1):\n",
    "            foundAA = int_to_char[i]\n",
    "    if(removeDummies == \"true\" and foundAA == '?'):\n",
    "        return alphabet[len(alphabet)-1]\n",
    "    return foundAA\n",
    "\n",
    "#input: [[[0,0,...,1,0,0] , ... , [0,1,0,0... 0]]]\n",
    "def retrieveString(onehot_encodedString):\n",
    "    #print(\"String\", onehot_encodedString)\n",
    "    foundString = \"\"\n",
    "    for k in range(len(onehot_encodedString)):\n",
    "        foundString = foundString + retrieveAA(onehot_encodedString[k])\n",
    "    return foundString\n",
    "\n",
    "def flattenedHotEncodingAAString(myString):\n",
    "    return np.array(hotEncodingAAString(myString)).flatten()\n",
    "\n",
    "#print(hotEncodingAAString(\"ACYD\")); \n",
    "#print(retrieveString(hotEncodingAAString(\"ACYD\")))\n",
    "#print(flattenedHotEncodingAAString(\"ACYD\"));\n",
    "#print(np.array(hotEncodingAAString(\"ACYD\")).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTwoColumnsFile(fileName):\n",
    "    balancedDataset = open(fileName, newline = '')   #one line is a text with \\t and \\n                                                                              \n",
    "    data_reader = csv.reader(balancedDataset, delimiter='\\t') #transform lines into lists \n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for line in data_reader:\n",
    "        if(not (line[0].startswith(\"CDR3\") or line[0].startswith(\"Slide\"))):\n",
    "            sequences.append(line[0])\n",
    "            labels.append(line[1])\n",
    "    \n",
    "    return (sequences, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Val dataset\n",
    "(sequences, labels) = readTwoColumnsFile(fileInput)\n",
    "\n",
    "# For shallow and ANN: flat one-hot      \n",
    "hotEncodedKeys = np.array(list(map(flattenedHotEncodingAAString, sequences)))\n",
    "# For CNN and LSTM: 2D one-hot        \n",
    "hotEncodedKeys2D = np.array(list(map(hotEncodingAAString, sequences)))\n",
    "\n",
    "binary = {\"Binder\": 1,\"NonBinder\": 0}\n",
    "binaryLabels = np.array([binary[item] for item in labels])\n",
    "\n",
    "if(condition == 3):\n",
    "    random.shuffle(binaryLabels)\n",
    "\n",
    "nSeqTot = len(hotEncodedKeys)\n",
    "train_size = int(0.8 * nSeqTot) \n",
    "test_size = int(0.2 * nSeqTot)\n",
    "\n",
    "possibleDataIDs = [*range(0,len(hotEncodedKeys))]\n",
    "random.shuffle(possibleDataIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#External test dataset\n",
    "(sequencesExt, labelsExt) = readTwoColumnsFile(fileInput)\n",
    "\n",
    "hotEncodedKeysExt = np.array(list(map(flattenedHotEncodingAAString, sequencesExt)))      \n",
    "hotEncodedKeys2DExt = np.array(list(map(hotEncodingAAString, sequencesExt)))\n",
    "binaryLabelsExt = np.array([binary[item] for item in labelsExt])\n",
    "\n",
    "#if(condition == 3):\n",
    "#    random.shuffle(binaryLabelsTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12104, 220)\n",
      "ML Task 7, fileInput  T7_1ADQ_A_Task1_SlicesBalancedData.txt_A.txt condition= 1\n",
      "Data Ready: tot= 15131  train= 12104 Counter({1: 6310, 0: 5794})  test= 3026 Counter({1: 1583, 0: 1443})\n",
      "LR ['NoLoss', 0.8213813615333774, 0.7558598568961263, 0.9709984152139461, 0.668547567993762, 0.8500277469478357] ['NoLoss', 0.8109715796430932, 0.7471882640586797, 0.965255843335439, 0.6476835970667141, 0.8423373759647189] ['NoLoss', 0.8193113475646024, 0.7541371158392435, 0.969850519381809, 0.6644014609753193, 0.8484982821677934]\n",
      "LSVM ['NoLoss', 0.9603436880370125, 0.9483235927406952, 0.9771790808240888, 0.9209016741959486, 0.9625351233218858] ['NoLoss', 0.949438202247191, 0.9349148418491484, 0.9709412507896399, 0.8992067063676314, 0.9525875426092346] ['NoLoss', 0.9581653558918776, 0.9456241561310912, 0.9759310869014441, 0.9165666282529751, 0.9605386197867963]\n",
      "SVM ['NoLoss', 0.9865333773959022, 0.9758476544356711, 0.9988906497622821, 0.9732860360625518, 0.9872347090610071] ['NoLoss', 0.9672835426305354, 0.9459134615384616, 0.9943145925457991, 0.9356177920137503, 0.9695103172158916] ['NoLoss', 0.9826845548873174, 0.9697193500738552, 0.9979731441601216, 0.965706993975376, 0.9836434011736797]\n",
      "RF ['NoLoss', 1.0, 1.0, 1.0, 1.0, 1.0] ['NoLoss', 0.9441506939854594, 0.9310975609756098, 0.9646241313960834, 0.888501589739513, 0.94756438101148] ['NoLoss', 0.9888308770074681, 0.9857879512011067, 0.9929060045604257, 0.9776400919787362, 0.9893341748185547]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-bce15f36241f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainKeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainKeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1405\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'processes'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m   1408\u001b[0m                                \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    760\u001b[0m                 \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"iprint\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"gtol\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"maxiter\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             )\n\u001b[1;32m--> 762\u001b[1;33m             n_iter_i = _check_optimize_result(\n\u001b[0m\u001b[0;32m    763\u001b[0m                 \u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m                 extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\utils\\optimize.py\u001b[0m in \u001b[0;36m_check_optimize_result\u001b[1;34m(solver, result, max_iter, extra_warning_msg)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[1;34m\"    https://scikit-learn.org/stable/modules/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m                 \u001b[1;34m\"preprocessing.html\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             ).format(solver, result.status, result.message.decode(\"latin1\"))\n\u001b[0m\u001b[0;32m    244\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_warning_msg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0mwarning_msg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mextra_warning_msg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "# First, 1D encodings for shallow models\n",
    "trainKeys = hotEncodedKeys[possibleDataIDs[0:train_size]].astype(float);\n",
    "trainLabels = binaryLabels[possibleDataIDs[0:train_size]];\n",
    "testKeys = hotEncodedKeys[possibleDataIDs[train_size: train_size + test_size]].astype(float);\n",
    "testLabels = binaryLabels[possibleDataIDs[train_size: train_size + test_size]];\n",
    "\n",
    "print(trainKeys.shape)\n",
    "print('ML Task 7, fileInput ', fileInput, 'condition=', condition)\n",
    "print(\"Data Ready: tot=\", nSeqTot,  \" train=\", len(trainKeys), str(Counter(trainLabels)), ' test=', len(testKeys), str(Counter(testLabels)))\n",
    "\n",
    "\n",
    "\n",
    "# Shallow architectures\n",
    "for architecture in [\"LR\", \"LSVM\", \"SVM\", \"RF\", \"AbsLR\", \"AbsRF\"]:\n",
    "\n",
    "    if(architecture == \"LR\"):\n",
    "        #L2 penalty\n",
    "        #tolerance 1e-4\n",
    "        #solver lbfgs\n",
    "        model = LogisticRegression(solver=\"lbfgs\", C=1e-4, penalty='l2')    #   class_weight='balanced')\n",
    "\n",
    "    if(architecture == \"LSVM\"):\n",
    "        #class sklearn.svm.LinearSVC(penalty='l2', loss='squared_hinge', \n",
    "        #Loss function = Squared hinge\n",
    "        #Tolerance = 1e-4\n",
    "        #C = Regularization float = 1.0\n",
    "        model = svm.LinearSVC(tol=1e-4, C = 1, loss='squared_hinge')\n",
    "\n",
    "    if(architecture == \"SVM\"):\n",
    "        #Kernel: Gaussian RBF\n",
    "        #Degree = 3\n",
    "        #Gamma = Scaled\n",
    "        #1/n_features * X.var()\n",
    "        #Tolerance = 1e-3\n",
    "        model = svm.SVC(kernel='rbf', degree=3, gamma='scale', tol=1e-3)\n",
    "\n",
    "    if(architecture == \"RF\"):\n",
    "        #Number trees = 150\n",
    "        #Criterion = Gini = mean decrease impurity\n",
    "        model = RandomForestClassifier(n_estimators=150, criterion=\"gini\")\n",
    "\n",
    "    if(architecture == \"AbsLR\"):\n",
    "        model = LogisticRegression(random_state=0)\n",
    "\n",
    "    if(architecture == \"AbsRF\"):\n",
    "        model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "\n",
    "    model.fit(trainKeys, trainLabels)\n",
    "\n",
    "    y_pred = model.predict(trainKeys)\n",
    "    metricMatTrain = [\"NoLoss\", accuracy_score(trainLabels, y_pred), precision_score(trainLabels, y_pred), recall_score(trainLabels, y_pred), \n",
    "                 matthews_corrcoef(trainLabels, y_pred), f1_score(trainLabels, y_pred)]#, model.score(testKeys, trainLabels)]\n",
    "\n",
    "    y_pred = model.predict(testKeys)\n",
    "    metricMat = [\"NoLoss\", accuracy_score(testLabels, y_pred), precision_score(testLabels, y_pred), recall_score(testLabels, y_pred), \n",
    "                 matthews_corrcoef(testLabels, y_pred), f1_score(testLabels, y_pred)]#, model.score(testKeys, testLabels)]\n",
    "\n",
    "    y_pred = model.predict(hotEncodedKeysExt)\n",
    "    metricMatExt = [\"NoLoss\", accuracy_score(binaryLabelsExt, y_pred), precision_score(binaryLabelsExt, y_pred), recall_score(binaryLabelsExt, y_pred), \n",
    "                 matthews_corrcoef(binaryLabelsExt, y_pred), f1_score(binaryLabelsExt, y_pred)]#, model.score(testKeys, binaryLabelsExt)]\n",
    "\n",
    "    \n",
    "    print(architecture, metricMatTrain, metricMat, metricMatExt)\n",
    "    \n",
    "    file_object = open('HistoryTask7.txt', 'a')\n",
    "    file_object.write(fileInput + \"\\t\" + architecture + \"\\t\" + str(condition) + \"\\t\" + str(metricMatTrain) + \"\\t\" + str(metricMat) + \"\\t\" + str(metricMatExt) + \"\\n\")\n",
    "    file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Input shape is (220,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 70)                15470     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 71        \n",
      "=================================================================\n",
      "Total params: 25,481\n",
      "Trainable params: 25,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\python\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "756/756 [==============================] - 1s 2ms/step - loss: 0.2067 - accuracy: 0.9187 - precision: 0.9222 - recall: 0.9224 - mcc_metric: 0.8404 - val_loss: 0.0289 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 2/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.1202 - accuracy: 0.9588 - precision: 0.9441 - recall: 0.9793 - mcc_metric: 0.9180 - val_loss: 0.0315 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 3/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0901 - accuracy: 0.9703 - precision: 0.9579 - recall: 0.9866 - mcc_metric: 0.9418 - val_loss: 0.2678 - val_accuracy: 0.9375 - val_precision: 0.8889 - val_recall: 1.0000 - val_mcc_metric: 0.8819\n",
      "Epoch 4/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0738 - accuracy: 0.9765 - precision: 0.9673 - recall: 0.9885 - mcc_metric: 0.9520 - val_loss: 0.1492 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.8889 - val_mcc_metric: 0.8819\n",
      "Epoch 5/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0608 - accuracy: 0.9815 - precision: 0.9736 - recall: 0.9915 - mcc_metric: 0.9623 - val_loss: 0.0046 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 6/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0539 - accuracy: 0.9830 - precision: 0.9774 - recall: 0.9904 - mcc_metric: 0.9652 - val_loss: 0.0129 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 7/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0457 - accuracy: 0.9864 - precision: 0.9811 - recall: 0.9930 - mcc_metric: 0.9724 - val_loss: 0.3513 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_mcc_metric: 0.8704\n",
      "Epoch 8/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0439 - accuracy: 0.9865 - precision: 0.9825 - recall: 0.9919 - mcc_metric: 0.9734 - val_loss: 0.0069 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 9/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0343 - accuracy: 0.9894 - precision: 0.9856 - recall: 0.9943 - mcc_metric: 0.9775 - val_loss: 0.0064 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 10/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0270 - accuracy: 0.9911 - precision: 0.9871 - recall: 0.9959 - mcc_metric: 0.9824 - val_loss: 0.0026 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 11/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0281 - accuracy: 0.9907 - precision: 0.9870 - recall: 0.9954 - mcc_metric: 0.9814 - val_loss: 0.0057 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 12/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0268 - accuracy: 0.9909 - precision: 0.9876 - recall: 0.9951 - mcc_metric: 0.9819 - val_loss: 0.0165 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 13/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0195 - accuracy: 0.9940 - precision: 0.9921 - recall: 0.9964 - mcc_metric: 0.9879 - val_loss: 0.0010 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 14/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0187 - accuracy: 0.9932 - precision: 0.9916 - recall: 0.9954 - mcc_metric: 0.9864 - val_loss: 0.1433 - val_accuracy: 0.9375 - val_precision: 0.8889 - val_recall: 1.0000 - val_mcc_metric: 0.8819\n",
      "Epoch 15/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0205 - accuracy: 0.9924 - precision: 0.9909 - recall: 0.9946 - mcc_metric: 0.9849 - val_loss: 0.3451 - val_accuracy: 0.8750 - val_precision: 0.8462 - val_recall: 1.0000 - val_mcc_metric: 0.7125\n",
      "Epoch 16/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0134 - accuracy: 0.9945 - precision: 0.9934 - recall: 0.9960 - mcc_metric: 0.9890 - val_loss: 0.0026 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 17/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0152 - accuracy: 0.9949 - precision: 0.9934 - recall: 0.9968 - mcc_metric: 0.9898 - val_loss: 0.0022 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 18/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0136 - accuracy: 0.9948 - precision: 0.9932 - recall: 0.9968 - mcc_metric: 0.9897 - val_loss: 0.0024 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 19/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0120 - accuracy: 0.9966 - precision: 0.9957 - recall: 0.9978 - mcc_metric: 0.9930 - val_loss: 0.4467 - val_accuracy: 0.9375 - val_precision: 0.8889 - val_recall: 1.0000 - val_mcc_metric: 0.8819\n",
      "Epoch 20/20\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0121 - accuracy: 0.9959 - precision: 0.9951 - recall: 0.9970 - mcc_metric: 0.9915 - val_loss: 1.4560e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "756/756 [==============================] - 1s 956us/step - loss: 0.0037 - accuracy: 0.9992 - precision: 0.9984 - recall: 1.0000 - mcc_metric: 0.99840s - loss: 0.0041 - accuracy: 0.9991 - precision: 0.9982 - recall: 1.0000 - mcc_metr\n",
      "189/189 [==============================] - 0s 948us/step - loss: 0.1942 - accuracy: 0.9676 - precision: 0.9509 - recall: 0.9885 - mcc_metric: 0.9350\n",
      "945/945 [==============================] - 1s 1ms/step - loss: 0.0418 - accuracy: 0.9929 - precision: 0.9887 - recall: 0.9977 - mcc_metric: 0.5859\n",
      "ANN [0.0036760836374014616, 0.9991732835769653, 0.9984214901924133, 1.0, 0.9984237551689148] noF1 [0.19419437646865845, 0.9675925970077515, 0.9508599638938904, 0.9885057210922241, 0.9350371360778809] noF1 [0.04177969694137573, 0.9928571581840515, 0.9887019991874695, 0.9977197647094727, 0.5859454870223999] noF1\n",
      "756/756 [==============================] - 1s 874us/step - loss: 0.0037 - accuracy: 0.9992 - precision: 0.9984 - recall: 1.0000 - mcc_metric: 0.9983\n",
      "189/189 [==============================] - 0s 871us/step - loss: 0.1942 - accuracy: 0.9676 - precision: 0.9508 - recall: 0.9885 - mcc_metric: 0.9359\n",
      "945/945 [==============================] - 1s 996us/step - loss: 0.0418 - accuracy: 0.9929 - precision: 0.9887 - recall: 0.9977 - mcc_metric: 0.5997\n",
      "CNN Input shape is (11, 20)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 9, 400)            24400     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 9, 400)            480400    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 9, 400)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 8, 400)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                160050    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 664,901\n",
      "Trainable params: 664,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "756/756 [==============================] - 6s 9ms/step - loss: 0.1737 - accuracy: 0.9339 - precision: 0.9203 - recall: 0.9564 - mcc_metric: 0.8711 - val_loss: 0.1076 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9167 - val_mcc_metric: 0.8563\n",
      "Epoch 2/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.1188 - accuracy: 0.9573 - precision: 0.9412 - recall: 0.9796 - mcc_metric: 0.9144 - val_loss: 0.0499 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 3/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.1059 - accuracy: 0.9625 - precision: 0.9478 - recall: 0.9824 - mcc_metric: 0.9246 - val_loss: 0.3109 - val_accuracy: 0.8750 - val_precision: 0.7778 - val_recall: 1.0000 - val_mcc_metric: 0.7778\n",
      "Epoch 4/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0972 - accuracy: 0.9669 - precision: 0.9546 - recall: 0.9835 - mcc_metric: 0.9331 - val_loss: 0.1656 - val_accuracy: 0.9375 - val_precision: 0.8571 - val_recall: 1.0000 - val_mcc_metric: 0.8783\n",
      "Epoch 5/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0885 - accuracy: 0.9720 - precision: 0.9607 - recall: 0.9867 - mcc_metric: 0.9440 - val_loss: 0.0169 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 6/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0816 - accuracy: 0.9707 - precision: 0.9595 - recall: 0.9855 - mcc_metric: 0.9411 - val_loss: 0.0512 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 7/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0801 - accuracy: 0.9732 - precision: 0.9640 - recall: 0.9856 - mcc_metric: 0.9461 - val_loss: 0.0950 - val_accuracy: 0.9375 - val_precision: 0.8750 - val_recall: 1.0000 - val_mcc_metric: 0.8819\n",
      "Epoch 8/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0720 - accuracy: 0.9757 - precision: 0.9650 - recall: 0.9894 - mcc_metric: 0.9510 - val_loss: 0.0464 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 9/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0701 - accuracy: 0.9763 - precision: 0.9688 - recall: 0.9864 - mcc_metric: 0.9525 - val_loss: 0.0114 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 10/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0652 - accuracy: 0.9778 - precision: 0.9695 - recall: 0.9888 - mcc_metric: 0.9551 - val_loss: 0.0321 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 11/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0674 - accuracy: 0.9783 - precision: 0.9707 - recall: 0.9885 - mcc_metric: 0.9566 - val_loss: 0.1976 - val_accuracy: 0.9375 - val_precision: 0.9000 - val_recall: 1.0000 - val_mcc_metric: 0.8783\n",
      "Epoch 12/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0621 - accuracy: 0.9802 - precision: 0.9732 - recall: 0.9894 - mcc_metric: 0.9608 - val_loss: 0.0043 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 13/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0534 - accuracy: 0.9829 - precision: 0.9774 - recall: 0.9902 - mcc_metric: 0.9656 - val_loss: 0.3261 - val_accuracy: 0.9375 - val_precision: 0.7500 - val_recall: 1.0000 - val_mcc_metric: 0.8321\n",
      "Epoch 14/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0546 - accuracy: 0.9819 - precision: 0.9751 - recall: 0.9907 - mcc_metric: 0.9644 - val_loss: 0.0170 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 15/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0508 - accuracy: 0.9826 - precision: 0.9769 - recall: 0.9900 - mcc_metric: 0.9650 - val_loss: 0.0010 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 16/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0515 - accuracy: 0.9831 - precision: 0.9765 - recall: 0.9915 - mcc_metric: 0.9668 - val_loss: 0.0016 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 17/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0461 - accuracy: 0.9840 - precision: 0.9782 - recall: 0.9916 - mcc_metric: 0.9681 - val_loss: 0.0018 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 18/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0471 - accuracy: 0.9846 - precision: 0.9789 - recall: 0.9919 - mcc_metric: 0.9693 - val_loss: 0.0357 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 19/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0411 - accuracy: 0.9868 - precision: 0.9810 - recall: 0.9940 - mcc_metric: 0.9736 - val_loss: 0.0266 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 20/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0374 - accuracy: 0.9866 - precision: 0.9814 - recall: 0.9932 - mcc_metric: 0.9732 - val_loss: 0.3892 - val_accuracy: 0.9375 - val_precision: 0.8571 - val_recall: 1.0000 - val_mcc_metric: 0.8783\n",
      "756/756 [==============================] - 2s 3ms/step - loss: 0.0252 - accuracy: 0.9911 - precision: 0.9833 - recall: 0.9998 - mcc_metric: 0.9825\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9765 - precision: 0.9605 - recall: 0.9955 - mcc_metric: 0.9528\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.0396 - accuracy: 0.9882 - precision: 0.9788 - recall: 0.9990 - mcc_metric: 0.5815\n",
      "CNN [0.025208188220858574, 0.9910714030265808, 0.9833489060401917, 0.9998417496681213, 0.9825463891029358] noF1 [0.09694855660200119, 0.9765211343765259, 0.9605425596237183, 0.9955271482467651, 0.9527878761291504] noF1 [0.03955976665019989, 0.9881613850593567, 0.9787709712982178, 0.9989863038063049, 0.5815234780311584] noF1\n",
      "756/756 [==============================] - 2s 3ms/step - loss: 0.0252 - accuracy: 0.9911 - precision: 0.9834 - recall: 0.9998 - mcc_metric: 0.9822\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9765 - precision: 0.9606 - recall: 0.9955 - mcc_metric: 0.9532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 3ms/step - loss: 0.0396 - accuracy: 0.9882 - precision: 0.9788 - recall: 0.9990 - mcc_metric: 0.5802 E\n",
      "LSTM Input shape is (11, 20)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 11, 40)            9760      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 11, 40)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 11, 40)            12960     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 11, 40)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 40)                12960     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 35,721\n",
      "Trainable params: 35,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "756/756 [==============================] - 8s 10ms/step - loss: 0.0808 - accuracy: 0.9048 - precision: 0.8813 - recall: 0.9453 - mcc_metric: 0.8105 - val_loss: 0.0146 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 2/20\n",
      "756/756 [==============================] - 6s 8ms/step - loss: 0.0536 - accuracy: 0.9390 - precision: 0.9159 - recall: 0.9726 - mcc_metric: 0.8795 - val_loss: 0.0537 - val_accuracy: 0.9375 - val_precision: 0.8571 - val_recall: 1.0000 - val_mcc_metric: 0.8783\n",
      "Epoch 3/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0463 - accuracy: 0.9478 - precision: 0.9261 - recall: 0.9783 - mcc_metric: 0.8968 - val_loss: 0.0804 - val_accuracy: 0.9375 - val_precision: 0.8750 - val_recall: 1.0000 - val_mcc_metric: 0.8819\n",
      "Epoch 4/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0426 - accuracy: 0.9503 - precision: 0.9300 - recall: 0.9786 - mcc_metric: 0.9024 - val_loss: 0.0238 - val_accuracy: 0.9375 - val_precision: 0.8889 - val_recall: 1.0000 - val_mcc_metric: 0.8819\n",
      "Epoch 5/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0406 - accuracy: 0.9525 - precision: 0.9322 - recall: 0.9804 - mcc_metric: 0.9064 - val_loss: 0.0480 - val_accuracy: 0.9375 - val_precision: 0.8889 - val_recall: 1.0000 - val_mcc_metric: 0.8819\n",
      "Epoch 6/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0382 - accuracy: 0.9549 - precision: 0.9355 - recall: 0.9813 - mcc_metric: 0.9110 - val_loss: 0.0020 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 7/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0361 - accuracy: 0.9578 - precision: 0.9378 - recall: 0.9845 - mcc_metric: 0.9155 - val_loss: 0.0097 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 8/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0338 - accuracy: 0.9596 - precision: 0.9416 - recall: 0.9837 - mcc_metric: 0.9192 - val_loss: 0.0422 - val_accuracy: 0.9375 - val_precision: 0.9167 - val_recall: 1.0000 - val_mcc_metric: 0.8563\n",
      "Epoch 9/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0310 - accuracy: 0.9640 - precision: 0.9480 - recall: 0.9853 - mcc_metric: 0.9291 - val_loss: 0.0314 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.9000 - val_mcc_metric: 0.8783\n",
      "Epoch 10/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0286 - accuracy: 0.9659 - precision: 0.9503 - recall: 0.9864 - mcc_metric: 0.9327 - val_loss: 0.0018 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 11/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0265 - accuracy: 0.9693 - precision: 0.9539 - recall: 0.9891 - mcc_metric: 0.9390 - val_loss: 0.0136 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 12/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0249 - accuracy: 0.9714 - precision: 0.9579 - recall: 0.9888 - mcc_metric: 0.9418 - val_loss: 0.0555 - val_accuracy: 0.9375 - val_precision: 0.8571 - val_recall: 1.0000 - val_mcc_metric: 0.8783\n",
      "Epoch 13/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0245 - accuracy: 0.9706 - precision: 0.9570 - recall: 0.9881 - mcc_metric: 0.9410 - val_loss: 0.0137 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 14/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0229 - accuracy: 0.9744 - precision: 0.9603 - recall: 0.9919 - mcc_metric: 0.9490 - val_loss: 0.0597 - val_accuracy: 0.9375 - val_precision: 0.8889 - val_recall: 1.0000 - val_mcc_metric: 0.8819\n",
      "Epoch 15/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0224 - accuracy: 0.9740 - precision: 0.9620 - recall: 0.9892 - mcc_metric: 0.9474 - val_loss: 0.0482 - val_accuracy: 0.9375 - val_precision: 0.9091 - val_recall: 1.0000 - val_mcc_metric: 0.8704\n",
      "Epoch 16/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0221 - accuracy: 0.9741 - precision: 0.9620 - recall: 0.9896 - mcc_metric: 0.9483 - val_loss: 0.0034 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 17/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0209 - accuracy: 0.9766 - precision: 0.9647 - recall: 0.9915 - mcc_metric: 0.9537 - val_loss: 0.0028 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 18/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0201 - accuracy: 0.9772 - precision: 0.9655 - recall: 0.9918 - mcc_metric: 0.9535 - val_loss: 0.0218 - val_accuracy: 0.9375 - val_precision: 0.9231 - val_recall: 1.0000 - val_mcc_metric: 0.8321\n",
      "Epoch 19/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0197 - accuracy: 0.9773 - precision: 0.9661 - recall: 0.9915 - mcc_metric: 0.9550 - val_loss: 7.9819e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "Epoch 20/20\n",
      "756/756 [==============================] - 7s 9ms/step - loss: 0.0185 - accuracy: 0.9788 - precision: 0.9691 - recall: 0.9911 - mcc_metric: 0.9579 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_mcc_metric: 1.0000\n",
      "756/756 [==============================] - 2s 3ms/step - loss: 0.0159 - accuracy: 0.9818 - precision: 0.9717 - recall: 0.9941 - mcc_metric: 0.9640\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9699 - precision: 0.9566 - recall: 0.9866 - mcc_metric: 0.9400\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.0177 - accuracy: 0.9794 - precision: 0.9687 - recall: 0.9927 - mcc_metric: 0.5579\n",
      "LSTM [0.01588013768196106, 0.9818121790885925, 0.9717112183570862, 0.9941483736038208, 0.9639810919761658] noF1 [0.024922668933868408, 0.9699074029922485, 0.9566026329994202, 0.9865728616714478, 0.9399897456169128] noF1 [0.017685526981949806, 0.9794312119483948, 0.968715250492096, 0.9926508069038391, 0.5579209923744202] noF1\n",
      "756/756 [==============================] - 2s 3ms/step - loss: 0.0159 - accuracy: 0.9818 - precision: 0.9717 - recall: 0.9941 - mcc_metric: 0.9636\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.0249 - accuracy: 0.9699 - precision: 0.9566 - recall: 0.9866 - mcc_metric: 0.9402\n",
      "945/945 [==============================] - 3s 3ms/step - loss: 0.0176 - accuracy: 0.9795 - precision: 0.9687 - recall: 0.9928 - mcc_metric: 0.5608\n"
     ]
    }
   ],
   "source": [
    "for architecture in [\"ANN\", \"CNN\", \"LSTM\"]:\n",
    "\n",
    "    #Lstm and CNN require 2D inputs \n",
    "    if(architecture == \"CNN\" or architecture == \"LSTM\"):\n",
    "        trainKeys = hotEncodedKeys2D[possibleDataIDs[0:train_size]].astype(float);\n",
    "        trainLabels = binaryLabels[possibleDataIDs[0:train_size]];\n",
    "        testKeys = hotEncodedKeys2D[possibleDataIDs[train_size: train_size + test_size]].astype(float);\n",
    "        testLabels = binaryLabels[possibleDataIDs[train_size: train_size + test_size]];\n",
    "        extKeys = hotEncodedKeys2DExt\n",
    "        extLabels = binaryLabelsExt\n",
    "    else: \n",
    "        extKeys = hotEncodedKeysExt\n",
    "        extLabels = binaryLabelsExt\n",
    "        \n",
    "    #Transform into TF data structures\n",
    "    TFkeysTrain = tf.data.Dataset.from_tensor_slices(trainKeys)\n",
    "    TFvalTrain = tf.data.Dataset.from_tensor_slices(trainLabels)\n",
    "    TFkeysTest = tf.data.Dataset.from_tensor_slices(testKeys)\n",
    "    TFvalTest = tf.data.Dataset.from_tensor_slices(testLabels)\n",
    "    TFkeysExt = tf.data.Dataset.from_tensor_slices(extKeys)\n",
    "    TFvalExt = tf.data.Dataset.from_tensor_slices(extLabels)\n",
    "\n",
    "    tfTrainElements = tf.data.Dataset.zip((TFkeysTrain, TFvalTrain))\n",
    "    tfTestElements = tf.data.Dataset.zip((TFkeysTest, TFvalTest))\n",
    "    tfExtElements = tf.data.Dataset.zip((TFkeysExt, TFvalExt))\n",
    "\n",
    "    input_shape = trainKeys[0].shape\n",
    "    print(architecture, \"Input shape is\", input_shape)\n",
    "        \n",
    "    if(architecture == \"ANN\"):\n",
    "        #Hidden layers: 3\n",
    "        #Nodes per layer = 70\n",
    "        #Activation = ReLu\n",
    "        #Dropout = 0.1\n",
    "        #Output = Sigmoid\n",
    "        #Optimizer = Adam\n",
    "        #Loss = Binary cross entropy\n",
    "        #Batch size = 16\n",
    "        #Epochs = 20\n",
    "        #in github, adam learning_rate=0.0001\n",
    "\n",
    "        model = tf.keras.Sequential();\n",
    "        model.add(tf.keras.layers.Dense(units=70,kernel_initializer='uniform',activation='relu',input_shape=input_shape))    \n",
    "        model.add(tf.keras.layers.Dropout(rate=0.1))\n",
    "        model.add(tf.keras.layers.Dense(units=70,kernel_initializer='uniform',activation='relu'))    \n",
    "        model.add(tf.keras.layers.Dropout(rate=0.1))\n",
    "        model.add(tf.keras.layers.Dense(units=70,kernel_initializer='uniform',activation='relu'))    \n",
    "        model.add(tf.keras.layers.Dropout(rate=0.1))\n",
    "        model.add(tf.keras.layers.Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "        loss = 'binary_crossentropy'\n",
    "        nEpochs = 20\n",
    "        batch_size = 16\n",
    "\n",
    "    #For CNN, should not flatten (takes 10x20 input)\n",
    "    if(architecture == \"CNN\"):\n",
    "        #Kernel size = 3\n",
    "        #Number filters = 400\n",
    "        #Pool size = 2\n",
    "        #Dense layer nodes = 50\n",
    "        #Activation = ReLu\n",
    "        #Dropout = 0.5\n",
    "        #Output = Sigmoid\n",
    "        #Optimizer = Adam\n",
    "        #Loss = Binary cross entropy\n",
    "        #Batch size = 16\n",
    "        #Epochs = 20\n",
    "        # In github, adam learning_rate=0.000075\n",
    "        regularizer = None\n",
    "\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.InputLayer(input_shape))    \n",
    "        model.add(tf.keras.layers.Conv1D(filters=400, kernel_size=3, input_shape=input_shape))    \n",
    "        model.add(tf.keras.layers.Conv1D(filters=400, kernel_size=3, strides=1, activation='relu', kernel_regularizer=regularizer, bias_regularizer=regularizer, padding='same'))    \n",
    "        model.add(tf.keras.layers.Dropout(rate=0.5))        \n",
    "        model.add(tf.keras.layers.MaxPool1D(pool_size=2, strides=1))\n",
    "        model.add(tf.keras.layers.Flatten()) \n",
    "        model.add(tf.keras.layers.Dense(units=50, activation='relu', kernel_regularizer=regularizer, bias_regularizer=regularizer))   \n",
    "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "        loss = 'binary_crossentropy'\n",
    "        nEpochs = 20\n",
    "        batch_size = 16\n",
    "\n",
    "    # The LSTM also should not be flattened\n",
    "    if(architecture == \"LSTM\"):\n",
    "        #l2_regularization=1e-4\n",
    "        regularizer=tf.keras.regularizers.l2(1e-4)\n",
    "        #regularizer=regularizers.L1L2(l1=0.0, l2=1e-4),\n",
    "\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.LSTM(units=40, return_sequences=True, bias_regularizer=regularizer, input_shape=input_shape))\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.1))\n",
    "        model.add(tf.keras.layers.LSTM(units=40, bias_regularizer=regularizer, return_sequences=True))\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.1))\n",
    "        model.add(tf.keras.layers.LSTM(units=40, bias_regularizer=regularizer, return_sequences=False))\n",
    "        model.add(tf.keras.layers.Dropout(rate=0.1))\n",
    "        model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "        loss = 'mean_squared_error'\n",
    "        nEpochs = 20\n",
    "        batch_size = 16\n",
    "\n",
    "    #https://stackoverflow.com/questions/56865344/how-do-i-calculate-the-matthews-correlation-coefficient-in-tensorflow\n",
    "    def mcc_metric(y_true, y_pred):\n",
    "        predicted = tf.cast(tf.greater(y_pred, 0.5), tf.float32)\n",
    "        true_pos = tf.math.count_nonzero(predicted * y_true)\n",
    "        true_neg = tf.math.count_nonzero((predicted - 1) * (y_true - 1))\n",
    "        false_pos = tf.math.count_nonzero(predicted * (y_true - 1))\n",
    "        false_neg = tf.math.count_nonzero((predicted - 1) * y_true)\n",
    "        x = tf.cast((true_pos + false_pos) * (true_pos + false_neg) \n",
    "          * (true_neg + false_pos) * (true_neg + false_neg), tf.float32)\n",
    "        return tf.cast((true_pos * true_neg) - (false_pos * false_neg), tf.float32) / (tf.sqrt(x) + 0.00000001)\n",
    "\n",
    "    metrics = ['accuracy','Precision', 'Recall', mcc_metric] #, mcc_metric]\n",
    "    #'FalseNegatives', 'FalsePositives', 'TrueNegatives', 'TruePositives',\n",
    "    # tfa.metrics.F1Score(num_classes=1, threshold=0.5, average='macro')\n",
    "    model.build(input_shape)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    model.summary()\n",
    "    \n",
    "    train_dataset = tfTrainElements.shuffle(train_size).batch(batch_size, drop_remainder=True)\n",
    "    test_dataset = tfTestElements.shuffle(test_size).batch(batch_size, drop_remainder=True)\n",
    "    ext_dataset = tfExtElements.shuffle(test_size).batch(batch_size, drop_remainder=True)\n",
    "    \n",
    "    history = model.fit(train_dataset, epochs=nEpochs, validation_data=test_dataset, validation_steps=1)\n",
    "    print(architecture, str(model.evaluate(train_dataset)), \"noF1\", str(model.evaluate(test_dataset)), \"noF1\", str(model.evaluate(ext_dataset)), \"noF1\")\n",
    "                  \n",
    "    file_object = open('HistoryTask7.txt', 'a')\n",
    "    file_object.write(fileInput + \"\\t\" + architecture + \"\\t\" + str(condition) + \"\\t\" + str(model.evaluate(train_dataset))+ \"\\tnoF1\\t\" + str(model.evaluate(test_dataset)) + \"\\t\" + \"noF1\" + \"\\t\" + str(model.evaluate(ext_dataset)) + \"noF1\\n\")\n",
    "    file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
